---
title: Welcome to my blog
---

one-hot:每个词只用一个维度 【0,1，0.。。】，相关意义无法表示
co-Occorence:上下文的稠密向量，缺点：某些词 

word-embedding:

N-gram：实际上用2或3，因为太长的句子，训练预料很少，也无法理解词之间的相似意义


激活函数的引入原因：没有激活函数的话，多层可以转化为单一的层

无标注数据中训练
